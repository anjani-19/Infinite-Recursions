{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdgyFrWtRJX4duPSX+6E7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjani-19/Infinite-Recursions/blob/main/Study_Mate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "Ewr4Hie_1nqM",
        "outputId": "ed57db75-6043-4407-a815-16a9aedd11d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0f9ca7391af579863e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0f9ca7391af579863e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# ==============================\n",
        "# 1) Install dependencies\n",
        "# ==============================\n",
        "!pip install gradio pymupdf sentence-transformers faiss-cpu ibm-watsonx-ai python-dotenv numpy gTTS -q\n",
        "\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "\n",
        "# --- Optional: watsonx ---\n",
        "_WATSONX_AVAILABLE = True\n",
        "try:\n",
        "    from ibm_watsonx_ai.foundation_models import Model\n",
        "    from ibm_watsonx_ai import Credentials\n",
        "except Exception:\n",
        "    _WATSONX_AVAILABLE = False\n",
        "\n",
        "# ---------------------------\n",
        "# PDF Extraction\n",
        "# ---------------------------\n",
        "def extract_pdf_text(file: io.BytesIO):\n",
        "    doc = fitz.open(stream=file.read(), filetype=\"pdf\")\n",
        "    pages = []\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text(\"text\").replace(\"\\u00ad\", \"\")\n",
        "        pages.append({\"text\": text, \"page\": i + 1})\n",
        "    return pages\n",
        "\n",
        "def clean_text(t: str) -> str:\n",
        "    return t.replace(\"\\r\", \" \").replace(\"\\n\\n\", \"\\n\").strip()\n",
        "\n",
        "# ---------------------------\n",
        "# Chunking\n",
        "# ---------------------------\n",
        "def chunk_text(text: str, chunk_size: int = 900, overlap: int = 150):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    step = max(1, chunk_size - overlap)\n",
        "    for start in range(0, len(words), step):\n",
        "        chunk_words = words[start:start + chunk_size]\n",
        "        if not chunk_words:\n",
        "            break\n",
        "        chunks.append(\" \".join(chunk_words))\n",
        "        if start + chunk_size >= len(words):\n",
        "            break\n",
        "    return chunks\n",
        "\n",
        "# ---------------------------\n",
        "# Embeddings + FAISS\n",
        "# ---------------------------\n",
        "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "faiss_index = None\n",
        "all_chunks = []\n",
        "recent_questions = []  # store last 5 questions\n",
        "\n",
        "def build_faiss(chunks):\n",
        "    global faiss_index, all_chunks\n",
        "    texts = [c[\"text\"] for c in chunks]\n",
        "    embs = embedder.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
        "    dim = embs.shape[1]\n",
        "    faiss_index = faiss.IndexFlatIP(dim)\n",
        "    faiss_index.add(embs)\n",
        "    all_chunks = chunks\n",
        "    return f\"‚úÖ {len(chunks)} chunks indexed.\"\n",
        "\n",
        "def top_k(query, k=5):\n",
        "    q = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
        "    D, I = faiss_index.search(q, k)\n",
        "    results = []\n",
        "    for idx, score in zip(I[0], D[0]):\n",
        "        if idx == -1: continue\n",
        "        results.append({**all_chunks[idx], \"score\": float(score)})\n",
        "    return results\n",
        "\n",
        "# ---------------------------\n",
        "# LLM: Watsonx (with fallback)\n",
        "# ---------------------------\n",
        "class WatsonxAnswerer:\n",
        "    def __init__(self):\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv(\"WATSONX_API_KEY\")\n",
        "        self.url = os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\")\n",
        "        self.project_id = os.getenv(\"WATSONX_PROJECT_ID\")\n",
        "        self.space_id = os.getenv(\"WATSONX_SPACE_ID\")\n",
        "        self.model_id = os.getenv(\"WATSONX_MODEL_ID\", \"mistralai/mixtral-8x7b-instruct-v01\")\n",
        "        self.ok = _WATSONX_AVAILABLE and all([self.api_key, self.url, self.project_id])\n",
        "        self._model = None\n",
        "        if self.ok:\n",
        "            try:\n",
        "                creds = Credentials(url=self.url, api_key=self.api_key)\n",
        "                params = {\"decoding_method\": \"greedy\", \"max_new_tokens\": 500, \"temperature\": 0.2}\n",
        "                self._model = Model(\n",
        "                    model_id=self.model_id,\n",
        "                    params=params,\n",
        "                    credentials=creds,\n",
        "                    project_id=self.project_id,\n",
        "                    space_id=self.space_id,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                self.ok = False\n",
        "                print(\"Watsonx init failed:\", e)\n",
        "\n",
        "    def answer(self, question, context_blocks):\n",
        "        system = \"You are StudyMate, a friendly academic tutor. Cite sources as (p.<page>).\"\n",
        "        context_text = \"\\n\\n\".join([f\"[Source p.{c['page']}] {c['text']}\" for c in context_blocks])\n",
        "        prompt = f\"{system}\\n\\nQuestion: {question}\\n\\nContext:\\n{context_text}\\n\"\n",
        "\n",
        "        if self.ok and self._model is not None:\n",
        "            try:\n",
        "                res = self._model.generate(prompt)\n",
        "                if hasattr(res, \"get_result\"):\n",
        "                    out = res.get_result()\n",
        "                    if isinstance(out, dict):\n",
        "                        text = (\n",
        "                            out.get(\"results\", [{}])[0].get(\"generated_text\")\n",
        "                            or out.get(\"generated_text\")\n",
        "                            or json.dumps(out)\n",
        "                        )\n",
        "                        return text\n",
        "                    return str(out)\n",
        "                return str(res)\n",
        "            except Exception as e:\n",
        "                print(\"Watsonx error:\", e)\n",
        "\n",
        "        return \"ü§ñ Relevant context:\\n\" + \"\\n\".join([c[\"text\"][:300] for c in context_blocks])\n",
        "\n",
        "answerer = WatsonxAnswerer()\n",
        "\n",
        "# ---------------------------\n",
        "# Extra Features\n",
        "# ---------------------------\n",
        "def summarize_pdf():\n",
        "    if not all_chunks:\n",
        "        return \"‚ö†Ô∏è Please upload and process PDFs first.\"\n",
        "    full_text = \" \".join([c[\"text\"] for c in all_chunks])[:3000]\n",
        "    return f\"üìë Summary:\\n{full_text[:1000]}...\"\n",
        "\n",
        "def export_notes(answer, context):\n",
        "    filename = \"StudyMate_Notes.txt\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(\"Answer:\\n\")\n",
        "        f.write(answer + \"\\n\\n\")\n",
        "        f.write(\"Context:\\n\")\n",
        "        f.write(context)\n",
        "    return filename\n",
        "\n",
        "def generate_flashcards():\n",
        "    if not all_chunks:\n",
        "        return \"‚ö†Ô∏è Please process PDFs first.\"\n",
        "    sample = \" \".join([c[\"text\"] for c in all_chunks[:3]])\n",
        "    return f\"üé¥ Example Flashcard:\\nQ: What is the main idea?\\nA: {sample[:200]}...\"\n",
        "\n",
        "def glossary_builder():\n",
        "    if not all_chunks:\n",
        "        return \"‚ö†Ô∏è Please process PDFs first.\"\n",
        "    words = \" \".join([c[\"text\"] for c in all_chunks])\n",
        "    unique_terms = list(set([w for w in words.split() if len(w) > 7]))[:10]\n",
        "    return \"üìò Glossary Terms:\\n\" + \"\\n\".join(unique_terms)\n",
        "\n",
        "def tts_answer(answer):\n",
        "    tts = gTTS(answer)\n",
        "    filename = \"answer.mp3\"\n",
        "    tts.save(filename)\n",
        "    return filename\n",
        "\n",
        "def process_pdfs(files):\n",
        "    docs = []\n",
        "    for f in files:\n",
        "        with open(f.name, \"rb\") as fobj:\n",
        "            pages = extract_pdf_text(io.BytesIO(fobj.read()))\n",
        "            for p in pages:\n",
        "                docs.append({\"text\": clean_text(p[\"text\"]), \"page\": p[\"page\"], \"doc\": os.path.basename(f.name)})\n",
        "    msg = build_faiss(docs)\n",
        "    return msg\n",
        "\n",
        "def ask_question(question):\n",
        "    if faiss_index is None:\n",
        "        return \"‚ö†Ô∏è Please upload and process PDFs first.\", \"\", []\n",
        "    hits = top_k(question, k=5)\n",
        "    answer = answerer.answer(question, hits)\n",
        "    refs = \"\\n\\n\".join([f\"üìñ {h['doc']} ‚Äì p.{h['page']} (score {h['score']:.3f})\\n{h['text'][:400]}\" for h in hits])\n",
        "\n",
        "    # track recent\n",
        "    recent_questions.append(question)\n",
        "    if len(recent_questions) > 5:\n",
        "        recent_questions.pop(0)\n",
        "\n",
        "    return answer, refs, recent_questions\n",
        "\n",
        "# ---------------------------\n",
        "# üé® Themed Gradio Interface\n",
        "# ---------------------------\n",
        "custom_css = \"\"\"\n",
        "body {\n",
        "    background: linear-gradient(135deg, #9d50bb, #6e48aa, #ff758c, #6a82fb);\n",
        "    font-family: 'Segoe UI', sans-serif;\n",
        "}\n",
        ".gr-button {\n",
        "    background: linear-gradient(90deg, #a18cd1, #fbc2eb);\n",
        "    color: white !important;\n",
        "    border: none !important;\n",
        "    font-weight: bold;\n",
        "    border-radius: 12px !important;\n",
        "}\n",
        ".gr-textbox, .gr-file {\n",
        "    border-radius: 12px !important;\n",
        "    border: 2px solid #a18cd1 !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=custom_css) as demo:\n",
        "    gr.Markdown(\"\"\"<div style='text-align: center;\n",
        "                    padding: 20px;\n",
        "                    background: linear-gradient(90deg, #ff758c, #6a82fb);\n",
        "                    color: white;\n",
        "                    border-radius: 12px;\n",
        "                    font-size: 28px;\n",
        "                    font-weight: bold;'>\n",
        "        üìò Welcome to StudyMate (Student Edition)\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "    with gr.Tab(\"üìÇ Upload PDFs\"):\n",
        "        pdfs = gr.File(file_types=[\".pdf\"], file_count=\"multiple\", label=\"Upload PDFs\")\n",
        "        process_btn = gr.Button(\"üöÄ Process PDFs\")\n",
        "        status = gr.Textbox(label=\"Status\")\n",
        "        process_btn.click(process_pdfs, inputs=pdfs, outputs=status)\n",
        "\n",
        "    with gr.Tab(\"üí¨ Ask Questions\"):\n",
        "        q = gr.Textbox(label=\"‚ùì Your Question\")\n",
        "        ask_btn = gr.Button(\"üí¨ Ask\")\n",
        "        ans = gr.Textbox(label=\"‚úÖ Answer\", lines=5)\n",
        "        ctx = gr.Textbox(label=\"üìñ Retrieved Context\", lines=10)\n",
        "        recent_out = gr.Textbox(label=\"üïí Recent Questions (last 5)\")\n",
        "        ask_btn.click(ask_question, inputs=q, outputs=[ans, ctx, recent_out])\n",
        "\n",
        "        # Text-to-speech\n",
        "        tts_btn = gr.Button(\"üîä Listen Answer\")\n",
        "        audio_out = gr.Audio()\n",
        "        tts_btn.click(tts_answer, inputs=ans, outputs=audio_out)\n",
        "\n",
        "        # Export notes\n",
        "        export_btn = gr.Button(\"üìù Export Notes\")\n",
        "        file_out = gr.File()\n",
        "        export_btn.click(export_notes, inputs=[ans, ctx], outputs=file_out)\n",
        "\n",
        "    with gr.Tab(\"‚≠ê Summarize PDF\"):\n",
        "        sum_btn = gr.Button(\"üìë Generate Summary\")\n",
        "        summary_out = gr.Textbox(label=\"Summary\", lines=10)\n",
        "        sum_btn.click(summarize_pdf, outputs=summary_out)\n",
        "\n",
        "    with gr.Tab(\"üé¥ Flashcards\"):\n",
        "        flash_btn = gr.Button(\"üé¥ Generate Flashcards\")\n",
        "        flash_out = gr.Textbox(label=\"Flashcards Preview\", lines=5)\n",
        "        flash_btn.click(generate_flashcards, outputs=flash_out)\n",
        "\n",
        "    with gr.Tab(\"üìò Glossary\"):\n",
        "        gloss_btn = gr.Button(\"üìò Build Glossary\")\n",
        "        gloss_out = gr.Textbox(label=\"Glossary Terms\", lines=10)\n",
        "        gloss_btn.click(glossary_builder, outputs=gloss_out)\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ]
}